# Comprehensive Alert Rules for WordPress EKS Platform
# These rules cover WordPress, Database, Cache, Infrastructure, and Cost monitoring

groups:
  # WordPress Application Alerts
  - name: wordpress.alerts
    rules:
      - alert: WordPressDown
        expr: up{job="wordpress"} == 0
        for: 1m
        labels:
          severity: critical
          component: wordpress
          team: platform
        annotations:
          summary: "WordPress application is down"
          description: "WordPress pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been down for more than 1 minute."
          runbook_url: "https://runbooks.example.com/wordpress-down"
          remediation: |
            1. Check pod status: kubectl get pods -n {{ $labels.namespace }}
            2. Check pod logs: kubectl logs {{ $labels.pod }} -n {{ $labels.namespace }}
            3. Check events: kubectl describe pod {{ $labels.pod }} -n {{ $labels.namespace }}

      - alert: WordPressHighResponseTime
        expr: histogram_quantile(0.95, rate(wordpress_http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          component: wordpress
          team: platform
        annotations:
          summary: "WordPress response time is high"
          description: "95th percentile response time for WordPress is {{ $value }}s (threshold: 2s) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/wordpress-high-response-time"
          remediation: |
            1. Check database performance
            2. Review cache hit rates
            3. Check for slow plugins
            4. Review resource utilization

      - alert: WordPressHighErrorRate
        expr: rate(wordpress_http_requests_total{status=~"5.."}[5m]) / rate(wordpress_http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          component: wordpress
          team: platform
        annotations:
          summary: "WordPress error rate is high"
          description: "WordPress error rate is {{ $value | humanizePercentage }} (threshold: 5%) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/wordpress-high-error-rate"
          remediation: |
            1. Check application logs for errors
            2. Verify database connectivity
            3. Check cache service health
            4. Review recent deployments

      - alert: WordPressLowCacheHitRate
        expr: rate(wordpress_cache_hits_total[5m]) / (rate(wordpress_cache_hits_total[5m]) + rate(wordpress_cache_misses_total[5m])) < 0.7
        for: 10m
        labels:
          severity: warning
          component: wordpress
          team: platform
        annotations:
          summary: "WordPress cache hit rate is low"
          description: "Cache hit rate is {{ $value | humanizePercentage }} (threshold: 70%) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/wordpress-low-cache-hit-rate"
          remediation: |
            1. Check Redis/ElastiCache health
            2. Review cache configuration
            3. Check for cache evictions
            4. Consider increasing cache size

      - alert: WordPressPluginSlowExecution
        expr: wordpress_plugin_execution_time_seconds > 1
        for: 5m
        labels:
          severity: warning
          component: wordpress
          team: development
        annotations:
          summary: "WordPress plugin execution is slow"
          description: "Plugin {{ $labels.plugin }} execution time is {{ $value }}s (threshold: 1s) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/wordpress-plugin-slow"
          remediation: |
            1. Review plugin code for optimization
            2. Check for database query issues
            3. Consider disabling or replacing plugin
            4. Profile plugin execution

  # Database Performance Alerts
  - name: database.alerts
    rules:
      - alert: DatabaseDown
        expr: up{job="mysql-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
          team: platform
        annotations:
          summary: "Database is down or unreachable"
          description: "MySQL exporter cannot reach database {{ $labels.instance }} for more than 1 minute."
          runbook_url: "https://runbooks.example.com/database-down"
          remediation: |
            1. Check Aurora cluster status in AWS Console
            2. Verify security group rules
            3. Check database credentials
            4. Review CloudWatch metrics for RDS

      - alert: DatabaseHighConnectionUsage
        expr: (mysql_global_status_threads_connected / mysql_global_variables_max_connections) > 0.8
        for: 5m
        labels:
          severity: warning
          component: database
          team: platform
        annotations:
          summary: "Database connection usage is high"
          description: "Database connection usage is {{ $value | humanizePercentage }} (threshold: 80%) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/database-high-connections"
          remediation: |
            1. Review application connection pooling
            2. Check for connection leaks
            3. Consider increasing max_connections
            4. Identify long-running queries

      - alert: DatabaseSlowQueries
        expr: rate(mysql_global_status_slow_queries[5m]) > 10
        for: 5m
        labels:
          severity: warning
          component: database
          team: development
        annotations:
          summary: "Database has high rate of slow queries"
          description: "Slow query rate is {{ $value }} queries/sec (threshold: 10/sec) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/database-slow-queries"
          remediation: |
            1. Enable slow query log
            2. Review query execution plans
            3. Check for missing indexes
            4. Optimize problematic queries

      - alert: DatabaseReplicationLag
        expr: mysql_slave_status_seconds_behind_master > 30
        for: 5m
        labels:
          severity: warning
          component: database
          team: platform
        annotations:
          summary: "Database replication lag is high"
          description: "Replication lag is {{ $value }}s (threshold: 30s) on replica {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/database-replication-lag"
          remediation: |
            1. Check replica instance performance
            2. Review network connectivity
            3. Check for long-running transactions
            4. Consider scaling replica instance

      - alert: DatabaseHighCPU
        expr: mysql_global_status_threads_running > 20
        for: 10m
        labels:
          severity: warning
          component: database
          team: platform
        annotations:
          summary: "Database CPU usage is high"
          description: "Database has {{ $value }} threads running (threshold: 20) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/database-high-cpu"
          remediation: |
            1. Identify resource-intensive queries
            2. Review query execution plans
            3. Check for table locks
            4. Consider scaling database instance

  # Redis/Cache Alerts
  - name: cache.alerts
    rules:
      - alert: RedisDown
        expr: up{job="redis-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          component: cache
          team: platform
        annotations:
          summary: "Redis cache is down or unreachable"
          description: "Redis exporter cannot reach cache {{ $labels.instance }} for more than 1 minute."
          runbook_url: "https://runbooks.example.com/redis-down"
          remediation: |
            1. Check ElastiCache cluster status
            2. Verify security group rules
            3. Check Redis AUTH configuration
            4. Review CloudWatch metrics

      - alert: RedisHighMemoryUsage
        expr: (redis_memory_used_bytes / redis_memory_max_bytes) > 0.85
        for: 5m
        labels:
          severity: warning
          component: cache
          team: platform
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis memory usage is {{ $value | humanizePercentage }} (threshold: 85%) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/redis-high-memory"
          remediation: |
            1. Review cache eviction policy
            2. Check for memory leaks
            3. Consider increasing cache size
            4. Review cache key TTLs

      - alert: RedisHighEvictionRate
        expr: rate(redis_evicted_keys_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
          component: cache
          team: platform
        annotations:
          summary: "Redis eviction rate is high"
          description: "Redis is evicting {{ $value }} keys/sec (threshold: 100/sec) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/redis-high-eviction"
          remediation: |
            1. Increase cache memory allocation
            2. Review cache key sizes
            3. Optimize cache usage patterns
            4. Consider cache partitioning

      - alert: RedisHighConnectionUsage
        expr: (redis_connected_clients / redis_config_maxclients) > 0.8
        for: 5m
        labels:
          severity: warning
          component: cache
          team: platform
        annotations:
          summary: "Redis connection usage is high"
          description: "Redis connection usage is {{ $value | humanizePercentage }} (threshold: 80%) on {{ $labels.instance }}."
          runbook_url: "https://runbooks.example.com/redis-high-connections"
          remediation: |
            1. Review application connection pooling
            2. Check for connection leaks
            3. Consider increasing maxclients
            4. Identify clients with many connections

  # Infrastructure - Node Health Alerts
  - name: node.alerts
    rules:
      - alert: NodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
          component: infrastructure
          team: platform
        annotations:
          summary: "Kubernetes node is not ready"
          description: "Node {{ $labels.node }} has been in NotReady state for more than 5 minutes."
          runbook_url: "https://runbooks.example.com/node-not-ready"
          remediation: |
            1. Check node status: kubectl describe node {{ $labels.node }}
            2. Check kubelet logs
            3. Verify node resources
            4. Check for network issues

      - alert: NodeHighCPU
        expr: (1 - avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.85
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Node CPU usage is high"
          description: "Node {{ $labels.instance }} CPU usage is {{ $value | humanizePercentage }} (threshold: 85%)."
          runbook_url: "https://runbooks.example.com/node-high-cpu"
          remediation: |
            1. Identify resource-intensive pods
            2. Check for CPU throttling
            3. Consider scaling cluster
            4. Review pod resource requests/limits

      - alert: NodeHighMemory
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) > 0.85
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Node memory usage is high"
          description: "Node {{ $labels.instance }} memory usage is {{ $value | humanizePercentage }} (threshold: 85%)."
          runbook_url: "https://runbooks.example.com/node-high-memory"
          remediation: |
            1. Identify memory-intensive pods
            2. Check for memory leaks
            3. Consider scaling cluster
            4. Review pod resource requests/limits

      - alert: NodeDiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) > 0.85
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Node disk space is low"
          description: "Node {{ $labels.instance }} disk usage is {{ $value | humanizePercentage }} (threshold: 85%) on {{ $labels.mountpoint }}."
          runbook_url: "https://runbooks.example.com/node-disk-space-low"
          remediation: |
            1. Clean up unused images: docker system prune
            2. Check for large log files
            3. Review pod ephemeral storage
            4. Consider increasing disk size

      - alert: NodeDiskIOHigh
        expr: rate(node_disk_io_time_seconds_total[5m]) > 0.9
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Node disk I/O is high"
          description: "Node {{ $labels.instance }} disk I/O utilization is {{ $value | humanizePercentage }} (threshold: 90%) on {{ $labels.device }}."
          runbook_url: "https://runbooks.example.com/node-disk-io-high"
          remediation: |
            1. Identify I/O intensive pods
            2. Check for disk performance issues
            3. Consider using faster storage class
            4. Review application I/O patterns

  # Infrastructure - Pod Health Alerts
  - name: pod.alerts
    rules:
      - alert: PodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
        for: 5m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Pod is crash looping"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently ({{ $value }} restarts/min)."
          runbook_url: "https://runbooks.example.com/pod-crash-looping"
          remediation: |
            1. Check pod logs: kubectl logs {{ $labels.pod }} -n {{ $labels.namespace }}
            2. Check events: kubectl describe pod {{ $labels.pod }} -n {{ $labels.namespace }}
            3. Review resource limits
            4. Check for application errors

      - alert: PodNotReady
        expr: kube_pod_status_phase{phase!~"Running|Succeeded"} > 0
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Pod is not ready"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in {{ $labels.phase }} state for more than 10 minutes."
          runbook_url: "https://runbooks.example.com/pod-not-ready"
          remediation: |
            1. Check pod status: kubectl get pod {{ $labels.pod }} -n {{ $labels.namespace }}
            2. Check events: kubectl describe pod {{ $labels.pod }} -n {{ $labels.namespace }}
            3. Check for image pull errors
            4. Verify resource availability

      - alert: PodHighCPUThrottling
        expr: rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.5
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Pod is experiencing high CPU throttling"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} is being throttled {{ $value | humanizePercentage }} of the time."
          runbook_url: "https://runbooks.example.com/pod-cpu-throttling"
          remediation: |
            1. Review CPU limits
            2. Consider increasing CPU limits
            3. Optimize application CPU usage
            4. Check for CPU-intensive operations

      - alert: PodHighMemoryUsage
        expr: (container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.9
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Pod memory usage is high"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} memory usage is {{ $value | humanizePercentage }} (threshold: 90%)."
          runbook_url: "https://runbooks.example.com/pod-high-memory"
          remediation: |
            1. Check for memory leaks
            2. Review memory limits
            3. Consider increasing memory limits
            4. Optimize application memory usage

      - alert: DeploymentReplicasMismatch
        expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
        for: 10m
        labels:
          severity: warning
          component: infrastructure
          team: platform
        annotations:
          summary: "Deployment replicas mismatch"
          description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has mismatched replicas."
          runbook_url: "https://runbooks.example.com/deployment-replicas-mismatch"
          remediation: |
            1. Check deployment status: kubectl get deployment {{ $labels.deployment }} -n {{ $labels.namespace }}
            2. Check pod status
            3. Review resource availability
            4. Check for scheduling issues

  # Cost Monitoring Alerts
  - name: cost.alerts
    rules:
      - alert: DailyCostThresholdExceeded
        expr: aws_cost_daily_usd > 500
        for: 1h
        labels:
          severity: warning
          component: cost
          team: finance
        annotations:
          summary: "Daily AWS cost threshold exceeded"
          description: "Daily AWS cost is ${{ $value }} (threshold: $500) for {{ $labels.service }} in {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/cost-threshold-exceeded"
          remediation: |
            1. Review AWS Cost Explorer for detailed breakdown
            2. Check for unexpected resource usage
            3. Review Karpenter spot instance usage
            4. Identify cost optimization opportunities

      - alert: MonthlyCostProjectionHigh
        expr: aws_cost_monthly_projection_usd > 15000
        for: 6h
        labels:
          severity: warning
          component: cost
          team: finance
        annotations:
          summary: "Monthly cost projection is high"
          description: "Projected monthly AWS cost is ${{ $value }} (threshold: $15000) for {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/monthly-cost-projection-high"
          remediation: |
            1. Review cost trends in Cost Explorer
            2. Identify cost spikes and anomalies
            3. Review resource utilization
            4. Implement cost optimization recommendations

      - alert: UnusedResourcesDetected
        expr: aws_cost_optimization_savings_usd > 1000
        for: 24h
        labels:
          severity: info
          component: cost
          team: platform
        annotations:
          summary: "Unused resources detected with potential savings"
          description: "Potential monthly savings of ${{ $value }} identified for {{ $labels.resource_type }} in {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/unused-resources"
          remediation: |
            1. Review AWS Cost Explorer recommendations
            2. Identify idle or underutilized resources
            3. Consider rightsizing or terminating resources
            4. Review EBS volumes and snapshots

      - alert: RDSCostIncreaseSignificant
        expr: (aws_cost_daily_usd{service="rds"} - aws_cost_daily_usd{service="rds"} offset 7d) / aws_cost_daily_usd{service="rds"} offset 7d > 0.3
        for: 6h
        labels:
          severity: warning
          component: cost
          team: platform
        annotations:
          summary: "RDS cost increased significantly"
          description: "RDS daily cost increased by {{ $value | humanizePercentage }} compared to last week in {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/rds-cost-increase"
          remediation: |
            1. Review Aurora Serverless v2 scaling patterns
            2. Check for unexpected query load
            3. Review backup and snapshot costs
            4. Consider optimizing database queries

      - alert: EC2SpotInstanceSavingsLow
        expr: (aws_cost_daily_usd{service="ec2",instance_type="spot"} / aws_cost_daily_usd{service="ec2"}) < 0.5
        for: 24h
        labels:
          severity: info
          component: cost
          team: platform
        annotations:
          summary: "EC2 spot instance usage is low"
          description: "Spot instance usage is {{ $value | humanizePercentage }} (target: >50%) in {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/spot-usage-low"
          remediation: |
            1. Review Karpenter NodePool configuration
            2. Check spot instance availability
            3. Adjust spot instance preferences
            4. Review workload spot compatibility

      - alert: EFSStorageCostHigh
        expr: aws_cost_daily_usd{service="efs"} > 50
        for: 24h
        labels:
          severity: warning
          component: cost
          team: platform
        annotations:
          summary: "EFS storage cost is high"
          description: "EFS daily cost is ${{ $value }} (threshold: $50) in {{ $labels.environment }}."
          runbook_url: "https://runbooks.example.com/efs-cost-high"
          remediation: |
            1. Review EFS storage usage and growth
            2. Consider EFS Lifecycle Management
            3. Clean up unused files
            4. Review access patterns for optimization
